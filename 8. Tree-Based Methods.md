# 7.1 Tree-based Methods

* Here we describe tree-based methods for regression and classification.
* These involve stratifying or segmenting the predictor space into a number of simple regions.
* Since the set of splitting rules used to segment the predictor space can be summarized in a tree, these types of approaches are known as **decision-tree methods**.

## 7.1.1 Pros and Cons
* Tree-based methods are simple and useful for interpretation.
* However, they are typically not competitive with the best supervised learning approaches in terms of prediction accuracy.
* Hence, in this chapter we also describe **bagging**, **random forests**, and **boosting**.
    * These methods grow multiple trees that are then combined to yield a single consensus prediction.
* Combining a large number of trees can often result in dramatic improvements in prediction accuracy at the expense of some loss in interpretation.

## 7.1.2 The Basics of Decision Trees
* Can be applied to both regression and classification problems.
* We first consider the case of regression, then move on to classification.